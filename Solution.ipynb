{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Aspect-based Sentiment Analysis using LSTM and Word Embeddings<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import gensim\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense,Input, Dropout\n",
    "from tensorflow.keras.layers import LSTM,Bidirectional\n",
    "from tensorflow.keras.optimizers import Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from given data (json) file into pandas dataframe\n",
    "train_data = pd.read_json(\"data/sentihood-train.json\")\n",
    "test_data = pd.read_json(\"data/sentihood-test.json\")\n",
    "# Split rows into multiple rows where multiple opinions are provided in this dataset\n",
    "train_data = train_data.explode('opinions',ignore_index=True)\n",
    "test_data = test_data.explode('opinions',ignore_index=True)\n",
    "# Drop rows with NaN values (where no opinion is provided)\n",
    "train_data.dropna(axis=0,inplace=True)\n",
    "test_data.dropna(axis=0,inplace=True)\n",
    "train_data.reset_index(drop=True,inplace=True)\n",
    "test_data.reset_index(drop=True,inplace=True)\n",
    "# Convert reviews into lowercased strings\n",
    "train_data['text'] = train_data['text'].str.lower()\n",
    "test_data['text'] = test_data['text'].str.lower()\n",
    "# Remove leading whitespaces from reviews\n",
    "train_data['text'] = train_data['text'].str.lstrip()\n",
    "test_data['text'] = test_data['text'].str.lstrip()\n",
    "# Insert a whitespace before and another one after wherever location1 or location2 appears\n",
    "train_data['text'] = train_data['text'].str.replace('.location1.',' location1 ',regex=True)\n",
    "test_data['text'] = test_data['text'].str.replace('.location1.',' location1 ',regex=True)\n",
    "train_data['text'] = train_data['text'].str.replace('.location2.',' location2 ',regex=True)\n",
    "test_data['text'] = test_data['text'].str.replace('.location2.',' location2 ',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opinions</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'sentiment': 'Negative', 'aspect': 'price', '...</td>\n",
       "      <td>1430</td>\n",
       "      <td>location1 is transforming and the prices will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'sentiment': 'Positive', 'aspect': 'shopping'...</td>\n",
       "      <td>2013</td>\n",
       "      <td>along location1 there are lots of electronics ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'sentiment': 'Positive', 'aspect': 'transit-l...</td>\n",
       "      <td>1244</td>\n",
       "      <td>and location1 is ten mins direct on the tube t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'sentiment': 'Positive', 'aspect': 'nightlife...</td>\n",
       "      <td>209</td>\n",
       "      <td>another option is location1 which is very cent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'sentiment': 'Positive', 'aspect': 'transit-l...</td>\n",
       "      <td>209</td>\n",
       "      <td>another option is location1 which is very cent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            opinions    id  \\\n",
       "0  {'sentiment': 'Negative', 'aspect': 'price', '...  1430   \n",
       "1  {'sentiment': 'Positive', 'aspect': 'shopping'...  2013   \n",
       "2  {'sentiment': 'Positive', 'aspect': 'transit-l...  1244   \n",
       "3  {'sentiment': 'Positive', 'aspect': 'nightlife...   209   \n",
       "4  {'sentiment': 'Positive', 'aspect': 'transit-l...   209   \n",
       "\n",
       "                                                text  \n",
       "0  location1 is transforming and the prices will ...  \n",
       "1  along location1 there are lots of electronics ...  \n",
       "2  and location1 is ten mins direct on the tube t...  \n",
       "3  another option is location1 which is very cent...  \n",
       "4  another option is location1 which is very cent...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A look at training data\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GloVe word embeddings into a dictionary (can be downloaded from here: https://nlp.stanford.edu/projects/glove/)\n",
    "gloveEmbeddings = {}\n",
    "with open('glove.twitter.27B/glove.twitter.27B.100d.txt','r',encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        l = line.split()\n",
    "        gloveEmbeddings[str(l[0])] = np.array(l[1:],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_tokens(text_column):\n",
    "    \"\"\"\n",
    "    Function to convert reviews into lists of tokens\n",
    "\n",
    "    args:\n",
    "        text_column(dataframe column)\n",
    "    \n",
    "    returns:\n",
    "        texts(a list of lists): each list contains tokens associated with a particular review\n",
    "        max_len(int): length of list with maximum number of tokens\n",
    "\"\"\"\n",
    "    texts = []\n",
    "    max_len = 0\n",
    "    tknzr = TweetTokenizer()\n",
    "    for text in text_column:\n",
    "        output = tknzr.tokenize(text) #tokenize review\n",
    "        i = 1\n",
    "        n = len(output)\n",
    "        #If tokenizer has tokenized 'location1' into 'location' and '1' (or 'location2' like this), concatenate them \n",
    "        while i < n:\n",
    "            if (output[i] == '1' or output[i] == '2') and output[i-1] == 'location':\n",
    "                output[i-1] = output[i-1]+output[i]\n",
    "                output.remove(output[i])\n",
    "                n = len(output)\n",
    "            i += 1\n",
    "        if len(output) > max_len:\n",
    "            max_len = len(output)\n",
    "        texts.append(output)\n",
    "    return (texts,max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts,max_len = text_to_tokens(train_data['text'])\n",
    "test_texts = text_to_tokens(test_data['text'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train custom Word2Vec word embeddings on training text in case some of the tokens are not there in downloaded GloVe vocabulary \n",
    "word_embeddings = gensim.models.Word2Vec(train_texts,min_count = 1,size=100,window = 3,iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_tensor(texts,gloveEmbeddings,wordEmbeddings,max_len):\n",
    "    \"\"\"\n",
    "    Function to convert list of lists of tokens into an array(padded) of word embeddings\n",
    "    \n",
    "    args:\n",
    "        texts(list of lists of tokens)\n",
    "        gloveEmbeddings(GloVe word vectors)\n",
    "        wordEmbeddings(Word2Vec word vectors)\n",
    "        max_len(int): length of sentence with maximum number of tokens\n",
    "        \n",
    "    returns:\n",
    "        array(float): Shape - number_of_reviews*max_len*length_of_word_embeddings(100)\n",
    "    \"\"\"\n",
    "    array = np.zeros((len(texts),max_len,100),dtype=np.float32)\n",
    "    for i in range(len(texts)):\n",
    "        for j in range(len(texts[i])):\n",
    "            if texts[i][j] in gloveEmbeddings:\n",
    "                a = gloveEmbeddings[texts[i][j]].reshape(1,-1)\n",
    "            elif texts[i][j] in wordEmbeddings:\n",
    "                a = word_embeddings[texts[i][j]].reshape(1,-1)\n",
    "            else:\n",
    "                a = np.zeros((1,100))\n",
    "            array[i][j] = a\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-fdf34b280423>:19: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  elif texts[i][j] in wordEmbeddings:\n",
      "<ipython-input-8-fdf34b280423>:20: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  a = word_embeddings[texts[i][j]].reshape(1,-1)\n"
     ]
    }
   ],
   "source": [
    "train_input_data = text_to_tensor(train_texts,gloveEmbeddings,word_embeddings,max_len)\n",
    "test_input_data = text_to_tensor(test_texts,gloveEmbeddings,word_embeddings,max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare targets for model training\n",
    "\n",
    "# For sentiment training\n",
    "train_sentiment = np.zeros(len(train_data))\n",
    "test_sentiment = np.zeros((len(test_data)))\n",
    "aspect_dict = {} # For aspect training purposes (key:aspect,value:index of aspect)\n",
    "count = 0\n",
    "for i in range(len(train_data)):\n",
    "    train_sentiment[i] = 1 if train_data['opinions'][i]['sentiment'] == 'Positive' else 0\n",
    "    if not train_data['opinions'][i]['aspect'] in aspect_dict:\n",
    "        aspect_dict[train_data['opinions'][i]['aspect']] = count\n",
    "        count += 1\n",
    "for i in range(len(test_data)):\n",
    "    test_sentiment[i] = 1 if test_data['opinions'][i]['sentiment'] == 'Positive' else 0\n",
    "#For aspect training\n",
    "train_aspect = np.zeros((len(train_data),len(aspect_dict)))\n",
    "test_aspect = np.zeros((len(test_data),len(aspect_dict)))\n",
    "for i in range(len(train_data)):\n",
    "    train_aspect[i][aspect_dict[train_data['opinions'][i]['aspect']]] = 1\n",
    "for i in range(len(test_data)):\n",
    "    test_aspect[i][aspect_dict[test_data['opinions'][i]['aspect']]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare another input to our model i.e. target entity\n",
    "# train_target_entity contains index of target entity in the list of tokens of that particular review\n",
    "train_target_entity = np.empty((len(train_data),),dtype=int)\n",
    "test_target_entity = np.empty((len(test_data),),dtype=int)\n",
    "for i in range(len(train_data)):\n",
    "    train_target_entity[i] = train_texts[i].index(train_data['opinions'][i]['target_entity'].lower())\n",
    "for i in range(len(test_data)):\n",
    "    test_target_entity[i] = test_texts[i].index(test_data['opinions'][i]['target_entity'].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definiton\n",
    "input_1 = Input(shape=(max_len,100)) #train_input_data\n",
    "input_2 = Input(shape=(1,),dtype=tf.int32) #train_target_entity\n",
    "#Bidirectional LSTM layer applied to train_input_data\n",
    "#It's output(out) is a sequence of hidden states corresponding to each timestep\n",
    "out = Bidirectional(LSTM(128,return_sequences=True,return_state=True))(input_1)\n",
    "#hidden_seq is a sequence of hidden states corresponding to each timestep\n",
    "hidden_seq = out[0]\n",
    "#use the hidden state of the timestep corresponding to the position of the target entity in the input sentence\n",
    "hidden =  tf.gather(hidden_seq,input_2[0],axis=1)\n",
    "hidden = tf.squeeze(hidden,axis=1)\n",
    "#feed forward neural layer for further processing\n",
    "dense = Dense(64,activation='relu')(hidden)\n",
    "#Dropout for regularization purposes\n",
    "dense = Dropout(0.4)(dense)\n",
    "dense = Dense(32,activation='relu')(dense)\n",
    "dense = Dropout(0.4)(dense)\n",
    "#output_1 - Sentiment\n",
    "output_1 = Dense(1,activation='sigmoid',name='output_1')(dense)\n",
    "#output_2 - Aspect\n",
    "output_2 = Dense(len(aspect_dict),activation='softmax',name='output_2')(dense)\n",
    "model = Model(inputs=[input_1,input_2],outputs=[output_1,output_2],name=\"ABSA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ABSA\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 122, 100)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   [(None, 122, 256), ( 234496      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(1,)]               0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2 (TensorFlo [(None, 1, 256)]     0           bidirectional[0][0]              \n",
      "                                                                 tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze (TensorFlow [(None, 256)]        0           tf_op_layer_GatherV2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           16448       tf_op_layer_Squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           2080        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output_1 (Dense)                (None, 1)            33          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output_2 (Dense)                (None, 12)           396         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 253,453\n",
      "Trainable params: 253,453\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer : Adamax\n",
    "opt = Adamax(learning_rate=0.01)\n",
    "#BinaryCrossentropy for sentiment output and CategoricalCrossentropy for aspect output\n",
    "model.compile(loss = {'output_1':'BinaryCrossentropy','output_2':'CategoricalCrossentropy'},optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "54/54 [==============================] - 15s 280ms/step - loss: 2.8005 - output_1_loss: 0.6137 - output_2_loss: 2.1867 - output_1_accuracy: 0.7085 - output_2_accuracy: 0.3227\n",
      "Epoch 2/75\n",
      "54/54 [==============================] - 15s 275ms/step - loss: 2.6356 - output_1_loss: 0.5996 - output_2_loss: 2.0360 - output_1_accuracy: 0.7291 - output_2_accuracy: 0.3422\n",
      "Epoch 3/75\n",
      "54/54 [==============================] - 15s 287ms/step - loss: 2.5923 - output_1_loss: 0.5923 - output_2_loss: 2.0000 - output_1_accuracy: 0.7288 - output_2_accuracy: 0.3469\n",
      "Epoch 4/75\n",
      "54/54 [==============================] - 15s 284ms/step - loss: 2.5321 - output_1_loss: 0.5844 - output_2_loss: 1.9476 - output_1_accuracy: 0.7276 - output_2_accuracy: 0.3481\n",
      "Epoch 5/75\n",
      "54/54 [==============================] - 16s 291ms/step - loss: 2.4178 - output_1_loss: 0.5491 - output_2_loss: 1.8688 - output_1_accuracy: 0.7326 - output_2_accuracy: 0.3607\n",
      "Epoch 6/75\n",
      "54/54 [==============================] - 16s 292ms/step - loss: 2.3160 - output_1_loss: 0.5281 - output_2_loss: 1.7879 - output_1_accuracy: 0.7214 - output_2_accuracy: 0.3775\n",
      "Epoch 7/75\n",
      "54/54 [==============================] - 16s 289ms/step - loss: 2.2794 - output_1_loss: 0.5137 - output_2_loss: 1.7656 - output_1_accuracy: 0.7273 - output_2_accuracy: 0.3863\n",
      "Epoch 8/75\n",
      "54/54 [==============================] - 16s 288ms/step - loss: 2.2403 - output_1_loss: 0.5086 - output_2_loss: 1.7317 - output_1_accuracy: 0.7370 - output_2_accuracy: 0.3916\n",
      "Epoch 9/75\n",
      "54/54 [==============================] - 16s 290ms/step - loss: 2.1787 - output_1_loss: 0.4966 - output_2_loss: 1.6821 - output_1_accuracy: 0.7367 - output_2_accuracy: 0.3943\n",
      "Epoch 10/75\n",
      "54/54 [==============================] - 16s 289ms/step - loss: 2.1468 - output_1_loss: 0.4892 - output_2_loss: 1.6577 - output_1_accuracy: 0.7426 - output_2_accuracy: 0.4028\n",
      "Epoch 11/75\n",
      "54/54 [==============================] - 16s 288ms/step - loss: 2.1138 - output_1_loss: 0.4764 - output_2_loss: 1.6373 - output_1_accuracy: 0.7400 - output_2_accuracy: 0.4161\n",
      "Epoch 12/75\n",
      "54/54 [==============================] - 16s 288ms/step - loss: 2.0603 - output_1_loss: 0.4757 - output_2_loss: 1.5846 - output_1_accuracy: 0.7550 - output_2_accuracy: 0.4231\n",
      "Epoch 13/75\n",
      "54/54 [==============================] - 15s 280ms/step - loss: 1.9927 - output_1_loss: 0.4573 - output_2_loss: 1.5355 - output_1_accuracy: 0.7571 - output_2_accuracy: 0.4482\n",
      "Epoch 14/75\n",
      "54/54 [==============================] - 15s 275ms/step - loss: 1.9595 - output_1_loss: 0.4563 - output_2_loss: 1.5032 - output_1_accuracy: 0.7644 - output_2_accuracy: 0.4541\n",
      "Epoch 15/75\n",
      "54/54 [==============================] - 15s 273ms/step - loss: 1.9503 - output_1_loss: 0.4487 - output_2_loss: 1.5016 - output_1_accuracy: 0.7680 - output_2_accuracy: 0.4711\n",
      "Epoch 16/75\n",
      "54/54 [==============================] - 16s 288ms/step - loss: 1.9269 - output_1_loss: 0.4579 - output_2_loss: 1.4689 - output_1_accuracy: 0.7659 - output_2_accuracy: 0.4956\n",
      "Epoch 17/75\n",
      "54/54 [==============================] - 16s 293ms/step - loss: 1.8276 - output_1_loss: 0.4425 - output_2_loss: 1.3850 - output_1_accuracy: 0.7777 - output_2_accuracy: 0.5065\n",
      "Epoch 18/75\n",
      "54/54 [==============================] - 16s 288ms/step - loss: 1.8087 - output_1_loss: 0.4339 - output_2_loss: 1.3748 - output_1_accuracy: 0.7797 - output_2_accuracy: 0.5168\n",
      "Epoch 19/75\n",
      "54/54 [==============================] - 15s 287ms/step - loss: 1.8037 - output_1_loss: 0.4274 - output_2_loss: 1.3763 - output_1_accuracy: 0.7853 - output_2_accuracy: 0.5130\n",
      "Epoch 20/75\n",
      "54/54 [==============================] - 16s 296ms/step - loss: 1.7387 - output_1_loss: 0.4159 - output_2_loss: 1.3229 - output_1_accuracy: 0.7812 - output_2_accuracy: 0.5194\n",
      "Epoch 21/75\n",
      "54/54 [==============================] - 16s 294ms/step - loss: 1.7365 - output_1_loss: 0.4189 - output_2_loss: 1.3175 - output_1_accuracy: 0.7862 - output_2_accuracy: 0.5247\n",
      "Epoch 22/75\n",
      "54/54 [==============================] - 16s 290ms/step - loss: 1.7060 - output_1_loss: 0.4208 - output_2_loss: 1.2853 - output_1_accuracy: 0.7809 - output_2_accuracy: 0.5362\n",
      "Epoch 23/75\n",
      "54/54 [==============================] - 16s 289ms/step - loss: 1.7015 - output_1_loss: 0.4185 - output_2_loss: 1.2830 - output_1_accuracy: 0.7862 - output_2_accuracy: 0.5465\n",
      "Epoch 24/75\n",
      "54/54 [==============================] - 16s 293ms/step - loss: 1.6530 - output_1_loss: 0.4133 - output_2_loss: 1.2397 - output_1_accuracy: 0.7856 - output_2_accuracy: 0.5512\n",
      "Epoch 25/75\n",
      "54/54 [==============================] - 16s 290ms/step - loss: 1.6459 - output_1_loss: 0.4152 - output_2_loss: 1.2308 - output_1_accuracy: 0.7883 - output_2_accuracy: 0.5657\n",
      "Epoch 26/75\n",
      "54/54 [==============================] - 15s 283ms/step - loss: 1.6263 - output_1_loss: 0.4113 - output_2_loss: 1.2150 - output_1_accuracy: 0.7871 - output_2_accuracy: 0.5639\n",
      "Epoch 27/75\n",
      "54/54 [==============================] - 16s 298ms/step - loss: 1.5915 - output_1_loss: 0.4036 - output_2_loss: 1.1878 - output_1_accuracy: 0.7953 - output_2_accuracy: 0.5710\n",
      "Epoch 28/75\n",
      "54/54 [==============================] - 19s 347ms/step - loss: 1.5641 - output_1_loss: 0.3929 - output_2_loss: 1.1712 - output_1_accuracy: 0.8024 - output_2_accuracy: 0.5648\n",
      "Epoch 29/75\n",
      "54/54 [==============================] - 16s 290ms/step - loss: 1.5447 - output_1_loss: 0.3911 - output_2_loss: 1.1535 - output_1_accuracy: 0.7980 - output_2_accuracy: 0.5754\n",
      "Epoch 30/75\n",
      "54/54 [==============================] - 16s 290ms/step - loss: 1.5293 - output_1_loss: 0.3874 - output_2_loss: 1.1419 - output_1_accuracy: 0.7965 - output_2_accuracy: 0.5798\n",
      "Epoch 31/75\n",
      "54/54 [==============================] - 16s 292ms/step - loss: 1.5241 - output_1_loss: 0.3961 - output_2_loss: 1.1280 - output_1_accuracy: 0.7948 - output_2_accuracy: 0.5789\n",
      "Epoch 32/75\n",
      "54/54 [==============================] - 16s 289ms/step - loss: 1.5084 - output_1_loss: 0.3915 - output_2_loss: 1.1168 - output_1_accuracy: 0.8051 - output_2_accuracy: 0.5904\n",
      "Epoch 33/75\n",
      "54/54 [==============================] - 16s 289ms/step - loss: 1.5494 - output_1_loss: 0.3969 - output_2_loss: 1.1526 - output_1_accuracy: 0.7900 - output_2_accuracy: 0.5839\n",
      "Epoch 34/75\n",
      "54/54 [==============================] - 16s 292ms/step - loss: 1.4791 - output_1_loss: 0.3779 - output_2_loss: 1.1013 - output_1_accuracy: 0.8101 - output_2_accuracy: 0.5948\n",
      "Epoch 35/75\n",
      "54/54 [==============================] - 16s 292ms/step - loss: 1.5018 - output_1_loss: 0.3907 - output_2_loss: 1.1110 - output_1_accuracy: 0.7983 - output_2_accuracy: 0.5939\n",
      "Epoch 36/75\n",
      "54/54 [==============================] - 16s 292ms/step - loss: 1.4584 - output_1_loss: 0.3739 - output_2_loss: 1.0845 - output_1_accuracy: 0.8080 - output_2_accuracy: 0.6034\n",
      "Epoch 37/75\n",
      "54/54 [==============================] - 16s 289ms/step - loss: 1.4432 - output_1_loss: 0.3758 - output_2_loss: 1.0675 - output_1_accuracy: 0.8101 - output_2_accuracy: 0.6081\n",
      "Epoch 38/75\n",
      "54/54 [==============================] - 16s 291ms/step - loss: 1.4427 - output_1_loss: 0.3690 - output_2_loss: 1.0737 - output_1_accuracy: 0.8045 - output_2_accuracy: 0.5963\n",
      "Epoch 39/75\n",
      "54/54 [==============================] - 15s 287ms/step - loss: 1.4440 - output_1_loss: 0.3847 - output_2_loss: 1.0593 - output_1_accuracy: 0.8071 - output_2_accuracy: 0.6084\n",
      "Epoch 40/75\n",
      "54/54 [==============================] - 16s 290ms/step - loss: 1.4118 - output_1_loss: 0.3629 - output_2_loss: 1.0489 - output_1_accuracy: 0.8110 - output_2_accuracy: 0.6048\n",
      "Epoch 41/75\n",
      "54/54 [==============================] - 16s 290ms/step - loss: 1.4246 - output_1_loss: 0.3762 - output_2_loss: 1.0484 - output_1_accuracy: 0.8071 - output_2_accuracy: 0.6092\n",
      "Epoch 42/75\n",
      "54/54 [==============================] - 16s 287ms/step - loss: 1.4019 - output_1_loss: 0.3613 - output_2_loss: 1.0406 - output_1_accuracy: 0.8118 - output_2_accuracy: 0.6137\n",
      "Epoch 43/75\n",
      "54/54 [==============================] - 15s 285ms/step - loss: 1.3624 - output_1_loss: 0.3554 - output_2_loss: 1.0069 - output_1_accuracy: 0.8104 - output_2_accuracy: 0.6243\n",
      "Epoch 44/75\n",
      "54/54 [==============================] - 16s 290ms/step - loss: 1.3737 - output_1_loss: 0.3495 - output_2_loss: 1.0242 - output_1_accuracy: 0.8216 - output_2_accuracy: 0.6119\n",
      "Epoch 45/75\n",
      "54/54 [==============================] - 17s 307ms/step - loss: 1.3555 - output_1_loss: 0.3537 - output_2_loss: 1.0018 - output_1_accuracy: 0.8204 - output_2_accuracy: 0.6196\n",
      "Epoch 46/75\n",
      "54/54 [==============================] - 15s 281ms/step - loss: 1.3368 - output_1_loss: 0.3536 - output_2_loss: 0.9832 - output_1_accuracy: 0.8157 - output_2_accuracy: 0.6237\n",
      "Epoch 47/75\n",
      "54/54 [==============================] - 15s 281ms/step - loss: 1.3679 - output_1_loss: 0.3599 - output_2_loss: 1.0081 - output_1_accuracy: 0.8130 - output_2_accuracy: 0.6240\n",
      "Epoch 48/75\n",
      "54/54 [==============================] - 15s 282ms/step - loss: 1.3152 - output_1_loss: 0.3439 - output_2_loss: 0.9713 - output_1_accuracy: 0.8283 - output_2_accuracy: 0.6299\n",
      "Epoch 49/75\n",
      "54/54 [==============================] - 15s 286ms/step - loss: 1.3205 - output_1_loss: 0.3526 - output_2_loss: 0.9679 - output_1_accuracy: 0.8195 - output_2_accuracy: 0.6310\n",
      "Epoch 50/75\n",
      "54/54 [==============================] - 15s 279ms/step - loss: 1.3225 - output_1_loss: 0.3507 - output_2_loss: 0.9718 - output_1_accuracy: 0.8204 - output_2_accuracy: 0.6366\n",
      "Epoch 51/75\n",
      "54/54 [==============================] - 15s 282ms/step - loss: 1.3039 - output_1_loss: 0.3387 - output_2_loss: 0.9653 - output_1_accuracy: 0.8319 - output_2_accuracy: 0.6384\n",
      "Epoch 52/75\n",
      "54/54 [==============================] - 15s 280ms/step - loss: 1.2893 - output_1_loss: 0.3420 - output_2_loss: 0.9473 - output_1_accuracy: 0.8271 - output_2_accuracy: 0.6434\n",
      "Epoch 53/75\n",
      "54/54 [==============================] - 15s 280ms/step - loss: 1.2948 - output_1_loss: 0.3432 - output_2_loss: 0.9516 - output_1_accuracy: 0.8227 - output_2_accuracy: 0.6322\n",
      "Epoch 54/75\n",
      "54/54 [==============================] - 15s 284ms/step - loss: 1.2510 - output_1_loss: 0.3298 - output_2_loss: 0.9212 - output_1_accuracy: 0.8319 - output_2_accuracy: 0.6558\n",
      "Epoch 55/75\n",
      "54/54 [==============================] - 15s 282ms/step - loss: 1.3012 - output_1_loss: 0.3356 - output_2_loss: 0.9656 - output_1_accuracy: 0.8236 - output_2_accuracy: 0.6307\n",
      "Epoch 56/75\n",
      "54/54 [==============================] - 16s 288ms/step - loss: 1.2631 - output_1_loss: 0.3443 - output_2_loss: 0.9188 - output_1_accuracy: 0.8277 - output_2_accuracy: 0.6443\n",
      "Epoch 57/75\n",
      "54/54 [==============================] - 16s 293ms/step - loss: 1.2411 - output_1_loss: 0.3273 - output_2_loss: 0.9138 - output_1_accuracy: 0.8301 - output_2_accuracy: 0.6440\n",
      "Epoch 58/75\n",
      "54/54 [==============================] - 16s 298ms/step - loss: 1.2726 - output_1_loss: 0.3446 - output_2_loss: 0.9280 - output_1_accuracy: 0.8342 - output_2_accuracy: 0.6472\n",
      "Epoch 59/75\n",
      "54/54 [==============================] - 15s 280ms/step - loss: 1.2262 - output_1_loss: 0.3234 - output_2_loss: 0.9028 - output_1_accuracy: 0.8407 - output_2_accuracy: 0.6543\n",
      "Epoch 60/75\n",
      "54/54 [==============================] - 15s 279ms/step - loss: 1.2263 - output_1_loss: 0.3309 - output_2_loss: 0.8954 - output_1_accuracy: 0.8392 - output_2_accuracy: 0.6567\n",
      "Epoch 61/75\n",
      "54/54 [==============================] - 15s 283ms/step - loss: 1.2253 - output_1_loss: 0.3201 - output_2_loss: 0.9052 - output_1_accuracy: 0.8354 - output_2_accuracy: 0.6469\n",
      "Epoch 62/75\n",
      "54/54 [==============================] - 15s 279ms/step - loss: 1.2075 - output_1_loss: 0.3128 - output_2_loss: 0.8948 - output_1_accuracy: 0.8422 - output_2_accuracy: 0.6446\n",
      "Epoch 63/75\n",
      "54/54 [==============================] - 15s 280ms/step - loss: 1.2266 - output_1_loss: 0.3208 - output_2_loss: 0.9059 - output_1_accuracy: 0.8416 - output_2_accuracy: 0.6499\n",
      "Epoch 64/75\n",
      "54/54 [==============================] - 15s 281ms/step - loss: 1.2115 - output_1_loss: 0.3134 - output_2_loss: 0.8981 - output_1_accuracy: 0.8316 - output_2_accuracy: 0.6463\n",
      "Epoch 65/75\n",
      "54/54 [==============================] - 15s 283ms/step - loss: 1.1963 - output_1_loss: 0.3081 - output_2_loss: 0.8882 - output_1_accuracy: 0.8366 - output_2_accuracy: 0.6528\n",
      "Epoch 66/75\n",
      "54/54 [==============================] - 15s 279ms/step - loss: 1.1920 - output_1_loss: 0.3057 - output_2_loss: 0.8862 - output_1_accuracy: 0.8448 - output_2_accuracy: 0.6528\n",
      "Epoch 67/75\n",
      "54/54 [==============================] - 15s 281ms/step - loss: 1.2194 - output_1_loss: 0.3102 - output_2_loss: 0.9092 - output_1_accuracy: 0.8551 - output_2_accuracy: 0.6567\n",
      "Epoch 68/75\n",
      "54/54 [==============================] - 15s 282ms/step - loss: 1.2036 - output_1_loss: 0.3172 - output_2_loss: 0.8863 - output_1_accuracy: 0.8422 - output_2_accuracy: 0.6434\n",
      "Epoch 69/75\n",
      "54/54 [==============================] - 15s 281ms/step - loss: 1.1720 - output_1_loss: 0.3064 - output_2_loss: 0.8656 - output_1_accuracy: 0.8472 - output_2_accuracy: 0.6493\n",
      "Epoch 70/75\n",
      "54/54 [==============================] - 15s 280ms/step - loss: 1.1757 - output_1_loss: 0.3107 - output_2_loss: 0.8650 - output_1_accuracy: 0.8431 - output_2_accuracy: 0.6578\n",
      "Epoch 71/75\n",
      "54/54 [==============================] - 15s 283ms/step - loss: 1.1473 - output_1_loss: 0.3046 - output_2_loss: 0.8427 - output_1_accuracy: 0.8484 - output_2_accuracy: 0.6593\n",
      "Epoch 72/75\n",
      "54/54 [==============================] - 15s 280ms/step - loss: 1.1268 - output_1_loss: 0.2992 - output_2_loss: 0.8276 - output_1_accuracy: 0.8501 - output_2_accuracy: 0.6670\n",
      "Epoch 73/75\n",
      "54/54 [==============================] - 15s 282ms/step - loss: 1.1649 - output_1_loss: 0.3034 - output_2_loss: 0.8615 - output_1_accuracy: 0.8445 - output_2_accuracy: 0.6602\n",
      "Epoch 74/75\n",
      "54/54 [==============================] - 15s 286ms/step - loss: 1.1477 - output_1_loss: 0.2952 - output_2_loss: 0.8526 - output_1_accuracy: 0.8528 - output_2_accuracy: 0.6564\n",
      "Epoch 75/75\n",
      "54/54 [==============================] - 16s 295ms/step - loss: 1.1655 - output_1_loss: 0.2949 - output_2_loss: 0.8706 - output_1_accuracy: 0.8531 - output_2_accuracy: 0.6493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1efb6b84ac0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train on training data\n",
    "model.fit([train_input_data,train_target_entity],[train_sentiment,train_aspect],batch_size=64,epochs = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 3s 57ms/step - loss: 1.8311 - output_1_loss: 0.5490 - output_2_loss: 1.2821 - output_1_accuracy: 0.7979 - output_2_accuracy: 0.6070\n",
      "Accuracy on Sentiment Prediction : 0.7978532910346985\n",
      "Accuracy on Aspect Prediction: 0.6070363521575928\n"
     ]
    }
   ],
   "source": [
    "#Evaluate on test data\n",
    "total_loss,sentiment_loss,aspect_loss,sentiment_acc,aspect_acc = model.evaluate([test_input_data,test_target_entity],[test_sentiment,test_aspect])\n",
    "print(\"Accuracy on Sentiment Prediction :\",sentiment_acc)\n",
    "print(\"Accuracy on Aspect Prediction:\",aspect_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another dictionary. Reverse the mapping of aspect_dict(helpful for writing preds.jsonl file)\n",
    "inv_aspect_dict = {value : key for key,value in aspect_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test set\n",
    "predictions = model.predict([test_input_data,test_target_entity])\n",
    "sentiment_pred = predictions[0]\n",
    "aspect_pred = predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of dictionaries(keys:sentiment,aspect,target_entity) for storing model predictions\n",
    "preds_list = []\n",
    "for i in range(len(test_data)):\n",
    "    d = {}\n",
    "    if sentiment_pred[i] < 0.5:\n",
    "        d['sentiment'] = 'Negative'\n",
    "    else:\n",
    "        d['sentiment'] = 'Positive'\n",
    "    for j in range(len(aspect_pred[1])):\n",
    "        max_prob = max(aspect_pred[i])\n",
    "        if aspect_pred[i][j] == max_prob:\n",
    "            d['aspect'] = inv_aspect_dict[j]\n",
    "            break\n",
    "    d['target_entity'] = test_data['opinions'][i]['target_entity']\n",
    "    preds_list.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add model predictions to the test_data dataframe\n",
    "test_data['model_pred'] = preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring test_data dataframe into required form\n",
    "new_test_data = test_data.groupby(test_data['id'],as_index=False,sort = False).aggregate({'opinions':lambda x : x.to_list(),'text':'first','model_pred':lambda x:x.to_list()})\n",
    "new_test_data = new_test_data[['opinions','id','text','model_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predictions to preds.jsonl file\n",
    "new_test_data.to_json(\"preds.jsonl\",orient = \"records\",lines=True,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times model got it right to the ground truth ratio for every aspect\n",
      "Price: 0.8924302788844621\n",
      "Shopping: 0.5641025641025641\n",
      "Transit-location: 0.5248868778280543\n",
      "Nightlife: 0.5454545454545454\n",
      "General: 0.5870307167235495\n",
      "Live: 0.6\n",
      "Safety: 0.6835443037974683\n",
      "Multicultural: 0.6274509803921569\n",
      "Green-nature: 0.2765957446808511\n",
      "Touristy: 0.23333333333333334\n",
      "Quiet: 0.16666666666666666\n",
      "Dining: 0.5135135135135135\n"
     ]
    }
   ],
   "source": [
    "#Analyzing results\n",
    "print(\"Times model got it right to the ground truth ratio for every aspect\")\n",
    "for asp in aspect_dict:\n",
    "    asp_count = 0\n",
    "    times_model_predicted_correct = 0\n",
    "    for i in range(len(test_data)):\n",
    "        if test_data['opinions'][i]['aspect'] == asp:\n",
    "            asp_count += 1\n",
    "            if test_data['model_pred'][i]['aspect'] == asp:\n",
    "                times_model_predicted_correct += 1\n",
    "    print(asp.capitalize()+\":\",times_model_predicted_correct/asp_count)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Point of Failure:**\n",
    "Model peforms weakly when a single target entity is evaluated on more than one aspect in a single review that may have arisen due to simplicity of this word embedding and LSTM-based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
