{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Aspect-based Sentiment Analysis using LSTM and Word Embeddings<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import gensim\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense,Input, Dropout\n",
    "from tensorflow.keras.layers import LSTM,Bidirectional\n",
    "from tensorflow.keras.optimizers import Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from given data (json) file into pandas dataframe\n",
    "train_data = pd.read_json(\"data/sentihood-train.json\")\n",
    "test_data = pd.read_json(\"data/sentihood-test.json\")\n",
    "# Split rows into multiple rows where multiple opinions are provided in this dataset\n",
    "train_data = train_data.explode('opinions',ignore_index=True)\n",
    "test_data = test_data.explode('opinions',ignore_index=True)\n",
    "# Drop rows with NaN values (where no opinion is provided)\n",
    "train_data.dropna(axis=0,inplace=True)\n",
    "test_data.dropna(axis=0,inplace=True)\n",
    "train_data.reset_index(drop=True,inplace=True)\n",
    "test_data.reset_index(drop=True,inplace=True)\n",
    "# Convert reviews into lowercased strings\n",
    "train_data['text'] = train_data['text'].str.lower()\n",
    "test_data['text'] = test_data['text'].str.lower()\n",
    "# Remove leading whitespaces from reviews\n",
    "train_data['text'] = train_data['text'].str.lstrip()\n",
    "test_data['text'] = test_data['text'].str.lstrip()\n",
    "# Insert a whitespace before and another one after wherever location1 or location2 appears\n",
    "train_data['text'] = train_data['text'].str.replace('.location1.',' location1 ',regex=True)\n",
    "test_data['text'] = test_data['text'].str.replace('.location1.',' location1 ',regex=True)\n",
    "train_data['text'] = train_data['text'].str.replace('.location2.',' location2 ',regex=True)\n",
    "test_data['text'] = test_data['text'].str.replace('.location2.',' location2 ',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opinions</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'sentiment': 'Negative', 'aspect': 'price', '...</td>\n",
       "      <td>1430</td>\n",
       "      <td>location1 is transforming and the prices will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'sentiment': 'Positive', 'aspect': 'shopping'...</td>\n",
       "      <td>2013</td>\n",
       "      <td>along location1 there are lots of electronics ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'sentiment': 'Positive', 'aspect': 'transit-l...</td>\n",
       "      <td>1244</td>\n",
       "      <td>and location1 is ten mins direct on the tube t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'sentiment': 'Positive', 'aspect': 'nightlife...</td>\n",
       "      <td>209</td>\n",
       "      <td>another option is location1 which is very cent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'sentiment': 'Positive', 'aspect': 'transit-l...</td>\n",
       "      <td>209</td>\n",
       "      <td>another option is location1 which is very cent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            opinions    id  \\\n",
       "0  {'sentiment': 'Negative', 'aspect': 'price', '...  1430   \n",
       "1  {'sentiment': 'Positive', 'aspect': 'shopping'...  2013   \n",
       "2  {'sentiment': 'Positive', 'aspect': 'transit-l...  1244   \n",
       "3  {'sentiment': 'Positive', 'aspect': 'nightlife...   209   \n",
       "4  {'sentiment': 'Positive', 'aspect': 'transit-l...   209   \n",
       "\n",
       "                                                text  \n",
       "0  location1 is transforming and the prices will ...  \n",
       "1  along location1 there are lots of electronics ...  \n",
       "2  and location1 is ten mins direct on the tube t...  \n",
       "3  another option is location1 which is very cent...  \n",
       "4  another option is location1 which is very cent...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A look at training data\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GloVe word embeddings into a dictionary (can be downloaded from here: https://nlp.stanford.edu/projects/glove/)\n",
    "gloveEmbeddings = {}\n",
    "with open('glove.twitter.27B/glove.twitter.27B.100d.txt','r',encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        l = line.split()\n",
    "        gloveEmbeddings[str(l[0])] = np.array(l[1:],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_tokens(text_column):\n",
    "    \"\"\"\n",
    "    Function to convert reviews into lists of tokens\n",
    "\n",
    "    args:\n",
    "        text_column(dataframe column)\n",
    "    \n",
    "    returns:\n",
    "        texts(a list of lists): each list contains tokens associated with a particular review\n",
    "        max_len(int): length of list with maximum number of tokens\n",
    "\"\"\"\n",
    "    texts = []\n",
    "    max_len = 0\n",
    "    tknzr = TweetTokenizer()\n",
    "    for text in text_column:\n",
    "        output = tknzr.tokenize(text)\n",
    "        i = 1\n",
    "        n = len(output)\n",
    "        #If tokenizer has tokenized 'location1' into 'location' and '1' (or 'location2' like this), concatenate them \n",
    "        while i < n:\n",
    "            if (output[i] == '1' or output[i] == '2') and output[i-1] == 'location':\n",
    "                output[i-1] = output[i-1]+output[i]\n",
    "                output.remove(output[i])\n",
    "                n = len(output)\n",
    "            i += 1\n",
    "        if len(output) > max_len:\n",
    "            max_len = len(output)\n",
    "        texts.append(output)\n",
    "    return (texts,max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts,max_len = text_to_tokens(train_data['text'])\n",
    "test_texts = text_to_tokens(test_data['text'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train custom Word2Vec word embeddings on training text in case some of the tokens are not there in downloaded GloVe vocabulary \n",
    "word_embeddings = gensim.models.Word2Vec(train_texts,min_count = 1,size=100,window = 3,iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_tensor(texts,gloveEmbeddings,wordEmbeddings,max_len):\n",
    "    \"\"\"\n",
    "    Function to convert list of lists of tokens into an array(padded) of word embeddings\n",
    "    \n",
    "    args:\n",
    "        texts(list of lists of tokens)\n",
    "        gloveEmbeddings(GloVe word vectors)\n",
    "        wordEmbeddings(Word2Vec word vectors)\n",
    "        max_len(int): length of sentence with maximum number of tokens\n",
    "        \n",
    "    returns:\n",
    "        array(float): Shape - number_of_reviews*max_len*length_of_word_embeddings(100)\n",
    "    \"\"\"\n",
    "    array = np.zeros((len(texts),max_len,100),dtype=np.float32)\n",
    "    for i in range(len(texts)):\n",
    "        for j in range(len(texts[i])):\n",
    "            if texts[i][j] in gloveEmbeddings:\n",
    "                a = gloveEmbeddings[texts[i][j]].reshape(1,-1)\n",
    "            elif texts[i][j] in wordEmbeddings:\n",
    "                a = word_embeddings[texts[i][j]].reshape(1,-1)\n",
    "            else:\n",
    "                a = np.zeros((1,100))\n",
    "            array[i][j] = a\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-fdf34b280423>:19: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  elif texts[i][j] in wordEmbeddings:\n",
      "<ipython-input-8-fdf34b280423>:20: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  a = word_embeddings[texts[i][j]].reshape(1,-1)\n"
     ]
    }
   ],
   "source": [
    "train_input_data = text_to_tensor(train_texts,gloveEmbeddings,word_embeddings,max_len)\n",
    "test_input_data = text_to_tensor(test_texts,gloveEmbeddings,word_embeddings,max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare targets for model training\n",
    "\n",
    "# For sentiment training\n",
    "train_sentiment = np.zeros(len(train_data))\n",
    "test_sentiment = np.zeros((len(test_data)))\n",
    "aspect_dict = {} # For aspect training purposes\n",
    "count = 0\n",
    "for i in range(len(train_data)):\n",
    "    train_sentiment[i] = 1 if train_data['opinions'][i]['sentiment'] == 'Positive' else 0\n",
    "    if not train_data['opinions'][i]['aspect'] in aspect_dict:\n",
    "        aspect_dict[train_data['opinions'][i]['aspect']] = count\n",
    "        count += 1\n",
    "for i in range(len(test_data)):\n",
    "    test_sentiment[i] = 1 if test_data['opinions'][i]['sentiment'] == 'Positive' else 0\n",
    "#For aspect training\n",
    "train_aspect = np.zeros((len(train_data),len(aspect_dict)))\n",
    "test_aspect = np.zeros((len(test_data),len(aspect_dict)))\n",
    "for i in range(len(train_data)):\n",
    "    train_aspect[i][aspect_dict[train_data['opinions'][i]['aspect']]] = 1\n",
    "for i in range(len(test_data)):\n",
    "    test_aspect[i][aspect_dict[test_data['opinions'][i]['aspect']]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare another input to our model i.e. target entity\n",
    "# train_target_entity contains index of target entity in the list of tokens of that particular review\n",
    "train_target_entity = np.empty((len(train_data),),dtype=int)\n",
    "test_target_entity = np.empty((len(test_data),),dtype=int)\n",
    "for i in range(len(train_data)):\n",
    "    train_target_entity[i] = train_texts[i].index(train_data['opinions'][i]['target_entity'].lower())\n",
    "for i in range(len(test_data)):\n",
    "    test_target_entity[i] = test_texts[i].index(test_data['opinions'][i]['target_entity'].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definiton\n",
    "input_1 = Input(shape=(max_len,100)) #train_input_data\n",
    "input_2 = Input(shape=(1,),dtype=tf.int32) #train_target_entity\n",
    "#Bidirectional LSTM layer applied to train_input_data\n",
    "#It's output(out) is a sequence of hidden states corresponding to each timestep\n",
    "out = Bidirectional(LSTM(128,return_sequences=True,return_state=True))(input_1)\n",
    "#hidden_seq is a sequence of hidden states corresponding to each timestep\n",
    "hidden_seq = out[0]\n",
    "#use the hidden state of the timestep corresponding to the position of the target entity in the input sentence\n",
    "hidden =  tf.gather(hidden_seq,input_2[0],axis=1)\n",
    "hidden = tf.squeeze(hidden,axis=1)\n",
    "#feed forward neural layer for further processing\n",
    "dense = Dense(64,activation='relu')(hidden)\n",
    "#Dropout for regularization purposes\n",
    "dense = Dropout(0.4)(dense)\n",
    "dense = Dense(32,activation='relu')(dense)\n",
    "dense = Dropout(0.4)(dense)\n",
    "#output_1 - Sentiment\n",
    "output_1 = Dense(1,activation='sigmoid',name='output_1')(dense)\n",
    "#output_2 - Aspect\n",
    "output_2 = Dense(len(aspect_dict),activation='softmax',name='output_2')(dense)\n",
    "model = Model(inputs=[input_1,input_2],outputs=[output_1,output_2],name=\"ABSA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ABSA\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 122, 100)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   [(None, 122, 256), ( 234496      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(1,)]               0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2 (TensorFlo [(None, 1, 256)]     0           bidirectional[0][0]              \n",
      "                                                                 tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze (TensorFlow [(None, 256)]        0           tf_op_layer_GatherV2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           16448       tf_op_layer_Squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           2080        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output_1 (Dense)                (None, 1)            33          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output_2 (Dense)                (None, 12)           396         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 253,453\n",
      "Trainable params: 253,453\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer : Adamax\n",
    "opt = Adamax(learning_rate=0.01)\n",
    "#BinaryCrossentropy for sentiment output and CategoricalCrossentropy for aspect output\n",
    "model.compile(loss = {'output_1':'BinaryCrossentropy','output_2':'CategoricalCrossentropy'},optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 16s 287ms/step - loss: 2.8045 - output_1_loss: 0.6172 - output_2_loss: 2.1872 - output_1_accuracy: 0.7061 - output_2_accuracy: 0.3124\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 16s 290ms/step - loss: 2.6000 - output_1_loss: 0.5899 - output_2_loss: 2.0101 - output_1_accuracy: 0.7264 - output_2_accuracy: 0.3478\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 16s 297ms/step - loss: 2.4294 - output_1_loss: 0.5452 - output_2_loss: 1.8842 - output_1_accuracy: 0.7320 - output_2_accuracy: 0.3560\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 17s 318ms/step - loss: 2.3430 - output_1_loss: 0.5372 - output_2_loss: 1.8058 - output_1_accuracy: 0.7314 - output_2_accuracy: 0.3654\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 17s 307ms/step - loss: 2.2543 - output_1_loss: 0.5122 - output_2_loss: 1.7421 - output_1_accuracy: 0.7415 - output_2_accuracy: 0.3778\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 18s 332ms/step - loss: 2.1798 - output_1_loss: 0.5050 - output_2_loss: 1.6749 - output_1_accuracy: 0.7418 - output_2_accuracy: 0.3978\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 18s 333ms/step - loss: 2.1109 - output_1_loss: 0.4777 - output_2_loss: 1.6331 - output_1_accuracy: 0.7577 - output_2_accuracy: 0.4234\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 19s 345ms/step - loss: 2.0452 - output_1_loss: 0.4824 - output_2_loss: 1.5628 - output_1_accuracy: 0.7582 - output_2_accuracy: 0.4558\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 18s 337ms/step - loss: 2.0046 - output_1_loss: 0.4765 - output_2_loss: 1.5281 - output_1_accuracy: 0.7597 - output_2_accuracy: 0.4558\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 15s 283ms/step - loss: 1.9844 - output_1_loss: 0.4688 - output_2_loss: 1.5155 - output_1_accuracy: 0.7603 - output_2_accuracy: 0.4706\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 17s 313ms/step - loss: 1.9363 - output_1_loss: 0.4560 - output_2_loss: 1.4803 - output_1_accuracy: 0.7718 - output_2_accuracy: 0.4782\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 16s 289ms/step - loss: 1.8756 - output_1_loss: 0.4519 - output_2_loss: 1.4237 - output_1_accuracy: 0.7733 - output_2_accuracy: 0.4988\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 15s 277ms/step - loss: 1.8636 - output_1_loss: 0.4481 - output_2_loss: 1.4155 - output_1_accuracy: 0.7736 - output_2_accuracy: 0.4938\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 15s 275ms/step - loss: 1.8485 - output_1_loss: 0.4481 - output_2_loss: 1.4004 - output_1_accuracy: 0.7683 - output_2_accuracy: 0.5006\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 15s 278ms/step - loss: 1.7955 - output_1_loss: 0.4287 - output_2_loss: 1.3668 - output_1_accuracy: 0.7824 - output_2_accuracy: 0.5147\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 15s 278ms/step - loss: 1.7959 - output_1_loss: 0.4379 - output_2_loss: 1.3581 - output_1_accuracy: 0.7768 - output_2_accuracy: 0.5162\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 15s 278ms/step - loss: 1.7603 - output_1_loss: 0.4347 - output_2_loss: 1.3256 - output_1_accuracy: 0.7750 - output_2_accuracy: 0.5374\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 15s 285ms/step - loss: 1.7212 - output_1_loss: 0.4292 - output_2_loss: 1.2920 - output_1_accuracy: 0.7768 - output_2_accuracy: 0.5527\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 15s 286ms/step - loss: 1.6928 - output_1_loss: 0.4260 - output_2_loss: 1.2669 - output_1_accuracy: 0.7783 - output_2_accuracy: 0.5557\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 17s 315ms/step - loss: 1.6644 - output_1_loss: 0.4233 - output_2_loss: 1.2411 - output_1_accuracy: 0.7812 - output_2_accuracy: 0.5562\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 16s 301ms/step - loss: 1.6689 - output_1_loss: 0.4177 - output_2_loss: 1.2512 - output_1_accuracy: 0.7845 - output_2_accuracy: 0.5654\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 17s 320ms/step - loss: 1.6182 - output_1_loss: 0.4131 - output_2_loss: 1.2051 - output_1_accuracy: 0.7898 - output_2_accuracy: 0.5674\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 16s 294ms/step - loss: 1.6261 - output_1_loss: 0.4167 - output_2_loss: 1.2095 - output_1_accuracy: 0.7889 - output_2_accuracy: 0.5627\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 16s 289ms/step - loss: 1.5867 - output_1_loss: 0.3994 - output_2_loss: 1.1872 - output_1_accuracy: 0.7909 - output_2_accuracy: 0.5701\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 15s 283ms/step - loss: 1.5701 - output_1_loss: 0.3970 - output_2_loss: 1.1730 - output_1_accuracy: 0.7977 - output_2_accuracy: 0.5716\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 15s 280ms/step - loss: 1.5535 - output_1_loss: 0.4016 - output_2_loss: 1.1518 - output_1_accuracy: 0.7886 - output_2_accuracy: 0.5754\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 15s 280ms/step - loss: 1.5480 - output_1_loss: 0.4025 - output_2_loss: 1.1455 - output_1_accuracy: 0.7895 - output_2_accuracy: 0.5857\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 15s 282ms/step - loss: 1.5258 - output_1_loss: 0.3866 - output_2_loss: 1.1392 - output_1_accuracy: 0.7933 - output_2_accuracy: 0.5878\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 17s 318ms/step - loss: 1.5335 - output_1_loss: 0.4054 - output_2_loss: 1.1281 - output_1_accuracy: 0.7927 - output_2_accuracy: 0.5916\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 17s 316ms/step - loss: 1.4862 - output_1_loss: 0.3814 - output_2_loss: 1.1049 - output_1_accuracy: 0.7965 - output_2_accuracy: 0.5957\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 18s 329ms/step - loss: 1.4368 - output_1_loss: 0.3766 - output_2_loss: 1.0603 - output_1_accuracy: 0.8077 - output_2_accuracy: 0.6069\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 18s 333ms/step - loss: 1.4724 - output_1_loss: 0.3815 - output_2_loss: 1.0909 - output_1_accuracy: 0.8048 - output_2_accuracy: 0.6066\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 18s 329ms/step - loss: 1.4304 - output_1_loss: 0.3695 - output_2_loss: 1.0609 - output_1_accuracy: 0.8071 - output_2_accuracy: 0.6066\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 17s 308ms/step - loss: 1.4809 - output_1_loss: 0.3790 - output_2_loss: 1.1019 - output_1_accuracy: 0.8036 - output_2_accuracy: 0.5933\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 17s 321ms/step - loss: 1.4451 - output_1_loss: 0.3715 - output_2_loss: 1.0736 - output_1_accuracy: 0.8180 - output_2_accuracy: 0.5969\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 17s 319ms/step - loss: 1.3871 - output_1_loss: 0.3584 - output_2_loss: 1.0288 - output_1_accuracy: 0.8154 - output_2_accuracy: 0.6172\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 16s 306ms/step - loss: 1.3952 - output_1_loss: 0.3623 - output_2_loss: 1.0329 - output_1_accuracy: 0.8165 - output_2_accuracy: 0.6131\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 16s 298ms/step - loss: 1.4009 - output_1_loss: 0.3744 - output_2_loss: 1.0266 - output_1_accuracy: 0.8057 - output_2_accuracy: 0.6095\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 16s 293ms/step - loss: 1.4046 - output_1_loss: 0.3663 - output_2_loss: 1.0383 - output_1_accuracy: 0.8115 - output_2_accuracy: 0.6110\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 16s 297ms/step - loss: 1.3690 - output_1_loss: 0.3558 - output_2_loss: 1.0132 - output_1_accuracy: 0.8189 - output_2_accuracy: 0.6237\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 16s 295ms/step - loss: 1.3740 - output_1_loss: 0.3587 - output_2_loss: 1.0153 - output_1_accuracy: 0.8174 - output_2_accuracy: 0.6198\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 17s 310ms/step - loss: 1.3266 - output_1_loss: 0.3568 - output_2_loss: 0.9698 - output_1_accuracy: 0.8192 - output_2_accuracy: 0.6296\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 16s 292ms/step - loss: 1.3314 - output_1_loss: 0.3512 - output_2_loss: 0.9802 - output_1_accuracy: 0.8192 - output_2_accuracy: 0.6237\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 16s 294ms/step - loss: 1.3289 - output_1_loss: 0.3396 - output_2_loss: 0.9893 - output_1_accuracy: 0.8295 - output_2_accuracy: 0.6278\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 16s 299ms/step - loss: 1.3345 - output_1_loss: 0.3460 - output_2_loss: 0.9885 - output_1_accuracy: 0.8204 - output_2_accuracy: 0.6290\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 16s 304ms/step - loss: 1.3398 - output_1_loss: 0.3487 - output_2_loss: 0.9912 - output_1_accuracy: 0.8148 - output_2_accuracy: 0.6237\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 16s 294ms/step - loss: 1.2904 - output_1_loss: 0.3340 - output_2_loss: 0.9564 - output_1_accuracy: 0.8292 - output_2_accuracy: 0.6304\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 16s 288ms/step - loss: 1.2611 - output_1_loss: 0.3293 - output_2_loss: 0.9318 - output_1_accuracy: 0.8310 - output_2_accuracy: 0.6443\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 17s 313ms/step - loss: 1.2853 - output_1_loss: 0.3310 - output_2_loss: 0.9544 - output_1_accuracy: 0.8269 - output_2_accuracy: 0.6328\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 16s 289ms/step - loss: 1.2447 - output_1_loss: 0.3253 - output_2_loss: 0.9194 - output_1_accuracy: 0.8313 - output_2_accuracy: 0.6360\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 15s 279ms/step - loss: 1.2727 - output_1_loss: 0.3368 - output_2_loss: 0.9359 - output_1_accuracy: 0.8257 - output_2_accuracy: 0.6360\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 16s 293ms/step - loss: 1.2771 - output_1_loss: 0.3299 - output_2_loss: 0.9472 - output_1_accuracy: 0.8310 - output_2_accuracy: 0.6390\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 17s 321ms/step - loss: 1.2568 - output_1_loss: 0.3279 - output_2_loss: 0.9289 - output_1_accuracy: 0.8313 - output_2_accuracy: 0.6340\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 15s 284ms/step - loss: 1.2435 - output_1_loss: 0.3216 - output_2_loss: 0.9219 - output_1_accuracy: 0.8274 - output_2_accuracy: 0.6531\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 15s 281ms/step - loss: 1.2236 - output_1_loss: 0.3150 - output_2_loss: 0.9086 - output_1_accuracy: 0.8354 - output_2_accuracy: 0.6366\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 15s 278ms/step - loss: 1.2380 - output_1_loss: 0.3185 - output_2_loss: 0.9195 - output_1_accuracy: 0.8369 - output_2_accuracy: 0.6490\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 15s 280ms/step - loss: 1.1953 - output_1_loss: 0.3057 - output_2_loss: 0.8896 - output_1_accuracy: 0.8416 - output_2_accuracy: 0.6499\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 15s 278ms/step - loss: 1.1803 - output_1_loss: 0.3013 - output_2_loss: 0.8790 - output_1_accuracy: 0.8516 - output_2_accuracy: 0.6484\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 15s 279ms/step - loss: 1.1994 - output_1_loss: 0.3042 - output_2_loss: 0.8952 - output_1_accuracy: 0.8428 - output_2_accuracy: 0.6484\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 15s 281ms/step - loss: 1.1981 - output_1_loss: 0.2993 - output_2_loss: 0.8987 - output_1_accuracy: 0.8525 - output_2_accuracy: 0.6393\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 15s 278ms/step - loss: 1.2122 - output_1_loss: 0.3057 - output_2_loss: 0.9065 - output_1_accuracy: 0.8501 - output_2_accuracy: 0.6413\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 15s 278ms/step - loss: 1.1953 - output_1_loss: 0.3014 - output_2_loss: 0.8939 - output_1_accuracy: 0.8501 - output_2_accuracy: 0.6461\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 15s 280ms/step - loss: 1.1748 - output_1_loss: 0.2949 - output_2_loss: 0.8799 - output_1_accuracy: 0.8534 - output_2_accuracy: 0.6434\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 15s 279ms/step - loss: 1.1388 - output_1_loss: 0.2867 - output_2_loss: 0.8522 - output_1_accuracy: 0.8551 - output_2_accuracy: 0.6587\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 16s 304ms/step - loss: 1.1548 - output_1_loss: 0.2994 - output_2_loss: 0.8553 - output_1_accuracy: 0.8422 - output_2_accuracy: 0.6519\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 15s 286ms/step - loss: 1.1703 - output_1_loss: 0.2966 - output_2_loss: 0.8738 - output_1_accuracy: 0.8569 - output_2_accuracy: 0.6590\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 16s 294ms/step - loss: 1.1641 - output_1_loss: 0.2875 - output_2_loss: 0.8766 - output_1_accuracy: 0.8522 - output_2_accuracy: 0.6416\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 16s 287ms/step - loss: 1.1236 - output_1_loss: 0.2802 - output_2_loss: 0.8434 - output_1_accuracy: 0.8545 - output_2_accuracy: 0.6599\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 15s 285ms/step - loss: 1.1196 - output_1_loss: 0.2827 - output_2_loss: 0.8369 - output_1_accuracy: 0.8516 - output_2_accuracy: 0.6634\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 16s 292ms/step - loss: 1.1230 - output_1_loss: 0.2839 - output_2_loss: 0.8392 - output_1_accuracy: 0.8522 - output_2_accuracy: 0.6590\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 17s 310ms/step - loss: 1.1618 - output_1_loss: 0.2985 - output_2_loss: 0.8633 - output_1_accuracy: 0.8501 - output_2_accuracy: 0.6634\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 15s 285ms/step - loss: 1.0949 - output_1_loss: 0.2767 - output_2_loss: 0.8182 - output_1_accuracy: 0.8584 - output_2_accuracy: 0.6699\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 16s 299ms/step - loss: 1.1259 - output_1_loss: 0.2841 - output_2_loss: 0.8417 - output_1_accuracy: 0.8566 - output_2_accuracy: 0.6572\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 15s 285ms/step - loss: 1.0909 - output_1_loss: 0.2719 - output_2_loss: 0.8190 - output_1_accuracy: 0.8631 - output_2_accuracy: 0.6670\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 16s 303ms/step - loss: 1.1313 - output_1_loss: 0.2771 - output_2_loss: 0.8542 - output_1_accuracy: 0.8637 - output_2_accuracy: 0.6575\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 15s 285ms/step - loss: 1.0790 - output_1_loss: 0.2705 - output_2_loss: 0.8085 - output_1_accuracy: 0.8663 - output_2_accuracy: 0.6614\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 16s 295ms/step - loss: 1.0993 - output_1_loss: 0.2765 - output_2_loss: 0.8227 - output_1_accuracy: 0.8648 - output_2_accuracy: 0.6581\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 16s 304ms/step - loss: 1.0807 - output_1_loss: 0.2706 - output_2_loss: 0.8101 - output_1_accuracy: 0.8637 - output_2_accuracy: 0.6622\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 16s 291ms/step - loss: 1.1063 - output_1_loss: 0.2746 - output_2_loss: 0.8317 - output_1_accuracy: 0.8566 - output_2_accuracy: 0.6561\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 16s 290ms/step - loss: 1.0729 - output_1_loss: 0.2631 - output_2_loss: 0.8098 - output_1_accuracy: 0.8660 - output_2_accuracy: 0.6690\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 15s 286ms/step - loss: 1.1155 - output_1_loss: 0.2823 - output_2_loss: 0.8332 - output_1_accuracy: 0.8569 - output_2_accuracy: 0.6617\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 16s 293ms/step - loss: 1.0632 - output_1_loss: 0.2648 - output_2_loss: 0.7984 - output_1_accuracy: 0.8651 - output_2_accuracy: 0.6708\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 16s 295ms/step - loss: 1.0882 - output_1_loss: 0.2673 - output_2_loss: 0.8209 - output_1_accuracy: 0.8637 - output_2_accuracy: 0.6622\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 15s 286ms/step - loss: 1.0412 - output_1_loss: 0.2584 - output_2_loss: 0.7828 - output_1_accuracy: 0.8701 - output_2_accuracy: 0.6678\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 16s 288ms/step - loss: 1.0659 - output_1_loss: 0.2722 - output_2_loss: 0.7937 - output_1_accuracy: 0.8640 - output_2_accuracy: 0.6729\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 17s 315ms/step - loss: 1.0597 - output_1_loss: 0.2605 - output_2_loss: 0.7991 - output_1_accuracy: 0.8645 - output_2_accuracy: 0.6655\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 15s 282ms/step - loss: 1.0483 - output_1_loss: 0.2545 - output_2_loss: 0.7939 - output_1_accuracy: 0.8704 - output_2_accuracy: 0.6611\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 15s 284ms/step - loss: 1.0698 - output_1_loss: 0.2662 - output_2_loss: 0.8035 - output_1_accuracy: 0.8675 - output_2_accuracy: 0.6693\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 16s 302ms/step - loss: 1.0762 - output_1_loss: 0.2644 - output_2_loss: 0.8118 - output_1_accuracy: 0.8654 - output_2_accuracy: 0.6578\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 15s 285ms/step - loss: 1.0513 - output_1_loss: 0.2683 - output_2_loss: 0.7830 - output_1_accuracy: 0.8651 - output_2_accuracy: 0.6720\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 16s 288ms/step - loss: 1.0349 - output_1_loss: 0.2499 - output_2_loss: 0.7850 - output_1_accuracy: 0.8696 - output_2_accuracy: 0.6667\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 16s 293ms/step - loss: 1.0659 - output_1_loss: 0.2545 - output_2_loss: 0.8114 - output_1_accuracy: 0.8725 - output_2_accuracy: 0.6658\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 16s 289ms/step - loss: 1.0507 - output_1_loss: 0.2547 - output_2_loss: 0.7959 - output_1_accuracy: 0.8707 - output_2_accuracy: 0.6608\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 16s 289ms/step - loss: 1.0700 - output_1_loss: 0.2739 - output_2_loss: 0.7960 - output_1_accuracy: 0.8513 - output_2_accuracy: 0.6652\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 16s 287ms/step - loss: 1.0549 - output_1_loss: 0.2596 - output_2_loss: 0.7953 - output_1_accuracy: 0.8651 - output_2_accuracy: 0.6646\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 17s 308ms/step - loss: 1.0831 - output_1_loss: 0.2561 - output_2_loss: 0.8270 - output_1_accuracy: 0.8698 - output_2_accuracy: 0.6575\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 19s 343ms/step - loss: 1.0893 - output_1_loss: 0.2846 - output_2_loss: 0.8047 - output_1_accuracy: 0.8595 - output_2_accuracy: 0.6678\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 17s 316ms/step - loss: 1.0534 - output_1_loss: 0.2544 - output_2_loss: 0.7990 - output_1_accuracy: 0.8648 - output_2_accuracy: 0.6661\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 15s 287ms/step - loss: 1.0458 - output_1_loss: 0.2565 - output_2_loss: 0.7894 - output_1_accuracy: 0.8669 - output_2_accuracy: 0.6776\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 16s 291ms/step - loss: 1.0391 - output_1_loss: 0.2544 - output_2_loss: 0.7847 - output_1_accuracy: 0.8701 - output_2_accuracy: 0.6687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x197b7f09af0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train on training data\n",
    "model.fit([train_input_data,train_target_entity],[train_sentiment,train_aspect],batch_size=64,epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 3s 56ms/step - loss: 2.0861 - output_1_loss: 0.6356 - output_2_loss: 1.4504 - output_1_accuracy: 0.8002 - output_2_accuracy: 0.6166\n",
      "Accuracy on Sentiment Prediction : 0.8002385497093201\n",
      "Accuracy on Aspect Prediction: 0.6165772080421448\n"
     ]
    }
   ],
   "source": [
    "#Evaluate on test data\n",
    "total_loss,sentiment_loss,aspect_loss,sentiment_acc,aspect_acc = model.evaluate([test_input_data,test_target_entity],[test_sentiment,test_aspect])\n",
    "print(\"Accuracy on Sentiment Prediction :\",sentiment_acc)\n",
    "print(\"Accuracy on Aspect Prediction:\",aspect_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another dictionary. Reverse the mapping of aspect_dict(helpful for writing preds.jsonl file)\n",
    "inv_aspect_dict = {value : key for key,value in aspect_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test set\n",
    "predictions = model.predict([test_input_data,test_target_entity])\n",
    "sentiment_pred = predictions[0]\n",
    "aspect_pred = predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of dictionaries(keys:sentiment,aspect,target_entity) for storing model predictions\n",
    "preds_list = []\n",
    "for i in range(len(test_data)):\n",
    "    d = {}\n",
    "    if sentiment_pred[i] == 0:\n",
    "        d['sentiment'] = 'Negative'\n",
    "    else:\n",
    "        d['sentiment'] = 'Positive'\n",
    "    for j in range(len(aspect_pred[1])):\n",
    "        max_prob = max(aspect_pred[i])\n",
    "        if aspect_pred[i][j] == max_prob:\n",
    "            d['aspect'] = inv_aspect_dict[j]\n",
    "            break\n",
    "    d['target_entity'] = test_data['opinions'][i]['target_entity']\n",
    "    preds_list.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add model predictions to the test_data dataframe\n",
    "test_data['model_pred'] = preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring test_data dataframe into required form\n",
    "new_test_data = test_data.groupby(test_data['id'],as_index=False,sort = False).aggregate({'opinions':lambda x : x.to_list(),'text':'first','model_pred':lambda x:x.to_list()})\n",
    "new_test_data = new_test_data[['opinions','id','text','model_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predictions to preds.jsonl file\n",
    "new_test_data.to_json(\"preds.jsonl\",orient = \"records\",lines=True,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times model got it right to the ground truth ratio for every aspect\n",
      "Price: 0.8685258964143426\n",
      "Shopping: 0.7307692307692307\n",
      "Transit-location: 0.6289592760180995\n",
      "Nightlife: 0.5584415584415584\n",
      "General: 0.5784982935153583\n",
      "Live: 0.5333333333333333\n",
      "Safety: 0.689873417721519\n",
      "Multicultural: 0.5098039215686274\n",
      "Green-nature: 0.3617021276595745\n",
      "Touristy: 0.3\n",
      "Quiet: 0.19444444444444445\n",
      "Dining: 0.3783783783783784\n"
     ]
    }
   ],
   "source": [
    "#Analyzing results\n",
    "print(\"Times model got it right to the ground truth ratio for every aspect\")\n",
    "for asp in aspect_dict:\n",
    "    asp_count = 0\n",
    "    times_model_predicted_correct = 0\n",
    "    for i in range(len(test_data)):\n",
    "        if test_data['opinions'][i]['aspect'] == asp:\n",
    "            asp_count += 1\n",
    "            if test_data['model_pred'][i]['aspect'] == asp:\n",
    "                times_model_predicted_correct += 1\n",
    "    print(asp.capitalize()+\":\",times_model_predicted_correct/asp_count)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Point of Failure:**\n",
    "Model peforms weakly when a single target entity is evaluated on more than one aspects in a single review that may have arisen due to simplicity of this word embedding and LSTM-based model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About my favourite Machine Learning library**\n",
    "\n",
    "My favourite machine learning library is NumPy. For most of the time that i have worked on machine learning projects, i have used NumPy for most of the part. NumPy provides great features to build machine learning models from scratch. Building machine learning models using NumPy from scratch reveals a great deal about the working of machine learning algorithms. And the slight dislikeness for it comes from the fact that there exists something like PyTorch that provides GPU support and has features like AutoGrad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
